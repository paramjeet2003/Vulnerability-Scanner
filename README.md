# Vulnerability-Scanner

## Description
This Python script is designed to perform automated web scanning. It can crawl a website to collect all possible links, extract forms from web pages, and test for vulnerabilities like Cross-Site Scripting (XSS). The script makes use of the `requests` library for HTTP requests, `re` for regular expression operations, `urllib.parse` for URL operations, and `BeautifulSoup` from `bs4` for parsing HTML.

## Features
- **Link Extraction**: Crawls a website and extracts all internal links.
- **Form Extraction**: Parses and extracts forms from web pages.
- **Vulnerability Testing**: Performs basic XSS vulnerability testing on forms and links.

## Requirements
- Python 3.x
- Libraries: `requests`, `BeautifulSoup4`, `re`, `urllib.parse`


## Usage
1. **Setting up the Script**:
   - Ensure Python 3.x is installed on your system.
   - Install the required Python libraries as mentioned above.
   - Download the script to your local machine.

2. **Running the Script**:
   - Open your terminal or command prompt.
   - Navigate to the directory containing the script.
   - Run the script by executing:
      ``` bash
            git clone https://github.com/paramjeet2003/Vulnerability-Scanner.git
            cd Vulnerability-Scanner
            chmod +x vuln_scanner.sh
            ./test.sh example.com
      ```
   - Replace example.com with the url you want to scan.

## Configurations
- **Ignore Links**: Specify any links you wish to ignore during the crawl in the initialization of the `vuln_scanner.py` file in `links_to_ignore` variable.

## Output
- The script prints extracted links, forms, and any vulnerabilities found directly to the console.
- It's configured to optionally write extracted links to a file named `spider` which is commented out by default.

## Disclaimer
- This tool is intended for educational purposes and ethical testing only.
- Ensure you have proper authorization before testing websites to avoid legal repercussions.

## Author
- Paramjeet Singh
